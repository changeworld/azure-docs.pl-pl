---
title: Informacje o formatach Apache Spark danych dla deweloperów Azure Data Lake Analytics U-SQL.
description: W tym artykule opisano Apache Spark pojęć, które ułatwiają deweloperom U_SQL zrozumienie różnic między formatami danych U-SQL i Spark.
author: guyhay
ms.author: guyhay
ms.reviewer: jasonh
ms.service: data-lake-analytics
ms.topic: conceptual
ms.custom: understand-apache-spark-data-formats
ms.date: 01/31/2019
ms.openlocfilehash: 36f39503ca32f1ee4b422ae7b1cf9abf48716f07
ms.sourcegitcommit: 359930a9387dd3d15d39abd97ad2b8cb69b8c18b
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 11/06/2019
ms.locfileid: "73648443"
---
# <a name="understand-differences-between-u-sql-and-spark-data-formats"></a>Zrozumienie różnic między formatami danych U-SQL i Spark

Jeśli chcesz użyć obu [Azure Databricks](../azure-databricks/what-is-azure-databricks.md) lub [Azure HDInsight Spark](../hdinsight/spark/apache-spark-overview.md), zalecamy przeprowadzenie migracji danych z [Azure Data Lake Storage Gen1](../data-lake-store/data-lake-store-overview.md) do [Azure Data Lake Storage Gen2](../storage/blobs/data-lake-storage-introduction.md).

Oprócz przechodzenia plików, warto również udostępnić dane przechowywane w tabelach U-SQL dostępnych dla platformy Spark.

## <a name="move-data-stored-in-azure-data-lake-storage-gen1-files"></a>Przenoszenie danych przechowywanych w plikach Azure Data Lake Storage Gen1

Dane przechowywane w plikach można przenosić na różne sposoby:

- Napisz potok [Azure Data Factory](../data-factory/introduction.md) , aby skopiować dane z konta [Azure Data Lake Storage Gen1](../data-lake-store/data-lake-store-overview.md) do konta [Azure Data Lake Storage Gen2](../storage/blobs/data-lake-storage-introduction.md) .
- Napisz zadanie Spark, które odczytuje dane z konta [Azure Data Lake Storage Gen1](../data-lake-store/data-lake-store-overview.md) i zapisuje je na koncie [Azure Data Lake Storage Gen2](../storage/blobs/data-lake-storage-introduction.md) . Na podstawie Twojego przypadku użycia możesz chcieć napisać go w innym formacie, takim jak Parquet, jeśli nie ma potrzeby zachowywania oryginalnego formatu pliku.

Zalecamy zapoznanie się z artykułem [Uaktualnianie rozwiązań do analizy danych Big Data z Azure Data Lake Storage Gen1 do Azure Data Lake Storage Gen2](../storage/blobs/data-lake-storage-upgrade.md)

## <a name="move-data-stored-in-u-sql-tables"></a>Przenoszenie danych przechowywanych w tabelach U-SQL

Tabele U-SQL nie są rozpoznawane przez platformę Spark. Jeśli przechowujesz dane w tabelach U-SQL, uruchomisz zadanie U-SQL, które wyodrębnia dane tabeli i zapisuje je w formacie, który jest rozpoznawany przez platformę Spark. Najbardziej odpowiednim formatem jest utworzenie zestawu plików Parquet po układ folderu magazyn metadanych Hive.

Dane wyjściowe można osiągnąć w języku U-SQL za pomocą wbudowanego wypełniania Parquet oraz przy użyciu dynamicznego partycjonowania danych wyjściowych z zestawami plików w celu utworzenia folderów partycji. [Przetwarzaj więcej plików niż kiedykolwiek, a korzystanie z Parquet](https://blogs.msdn.microsoft.com/azuredatalake/2018/06/11/process-more-files-than-ever-and-use-parquet-with-azure-data-lake-analytics) zawiera przykład sposobu tworzenia takich danych.

Po wykonaniu tej transformacji dane są kopiowane, jak opisano w rozdziale [przenoszenie danych przechowywanych w plikach Azure Data Lake Storage Gen1](#move-data-stored-in-azure-data-lake-storage-gen1-files).

## <a name="caveats"></a>Zastrzeżenia

- Semantyka danych podczas kopiowania plików kopia będzie miała miejsce na poziomie bajtów. Dlatego te same dane powinny być wyświetlane na koncie [Azure Data Lake Storage Gen2](../storage/blobs/data-lake-storage-introduction.md) . Należy jednak zauważyć, że platforma Spark może interpretować niektóre znaki inaczej. Na przykład w pliku CSV może być używana inna wartość domyślna dla ogranicznika wiersza.
    Ponadto, jeśli kopiujesz dane wpisane (z tabel), Parquet i Spark mogą mieć różną precyzję i skalę dla niektórych wartości z określonym typem (na przykład zmiennoprzecinkowych) i mogą traktować wartości null inaczej. Na przykład skrypt U-SQL ma C# semantykę wartości null, podczas gdy platforma Spark ma logikę z trzema wartościami null.

- Organizacja danych (partycjonowanie) tabele U-SQL zapewniają partycjonowanie na poziomie dwóch poziomów. Poziom zewnętrzny (`PARTITIONED BY`) ma wartość i jest mapowany głównie do schematu partycjonowania Hive/Spark przy użyciu hierarchii folderów. Musisz się upewnić, że wartości null są mapowane do właściwego folderu. Wewnętrzny poziom (`DISTRIBUTED BY`) w języku U-SQL oferuje 4 schematy dystrybucji: działania okrężne, zakres, mieszanie i mieszanie bezpośrednie.
    Tabele Hive/Spark obsługują tylko partycjonowanie i partycjonowanie skrótów przy użyciu innej funkcji mieszania niż U-SQL. Podczas wyprowadzania danych z tabeli U-SQL prawdopodobnie będziesz mieć możliwość mapowania na partycjonowanie wartości dla platformy Spark i może być konieczne przeprowadzenie dalszej strojenia układu danych w zależności od końcowych zapytań platformy Spark.

## <a name="next-steps"></a>Następne kroki

- [Zrozumienie koncepcji kodu platformy Spark dla deweloperów U-SQL](understand-spark-code-concepts.md)
- [Uaktualnij rozwiązania do analizy danych Big Data z Azure Data Lake Storage Gen1 do Azure Data Lake Storage Gen2](../storage/blobs/data-lake-storage-upgrade.md)
- [.NET dla Apache Spark](https://docs.microsoft.com/dotnet/spark/what-is-apache-spark-dotnet)
- [Przekształcanie danych przy użyciu działania Spark w Azure Data Factory](../data-factory/transform-data-using-spark.md)
- [Przekształcanie danych przy użyciu działania programu Hive platformy Hadoop w Azure Data Factory](../data-factory/transform-data-using-hadoop-hive.md)
- [Co to jest Apache Spark w usłudze Azure HDInsight](../hdinsight/spark/apache-spark-overview.md)
