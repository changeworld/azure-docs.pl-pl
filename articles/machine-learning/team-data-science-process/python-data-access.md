---
title: Dostęp do zestawów danych przy użyciu biblioteki klienta języka Python — zespół ds. procesów naukowych
description: Zainstaluj i użyj biblioteki klienta języka Python, aby bezpiecznie uzyskiwać dostęp do danych Azure Machine Learning i zarządzać nimi z poziomu lokalnego środowiska Python.
services: machine-learning
author: marktab
manager: cgronlun
editor: cgronlun
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 11/13/2017
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: e9daf1be1f931bb13cda446cbb9d6e37acce3bcf
ms.sourcegitcommit: c22327552d62f88aeaa321189f9b9a631525027c
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 11/04/2019
ms.locfileid: "73498101"
---
# <a name="access-datasets-with-python-using-the-azure-machine-learning-python-client-library"></a>Dostęp do zestawów danych z językiem Python za pomocą biblioteki klienta Python usługi Azure Machine Learning
Wersja zapoznawcza Microsoft Azure Machine Learning Biblioteka kliencka języka Python umożliwia bezpieczny dostęp do Azure Machine Learning zestawów danych ze środowiska lokalnego języka Python oraz umożliwia tworzenie zestawów danych i zarządzanie nimi w obszarze roboczym.

Ten temat zawiera instrukcje dotyczące:

* Zainstaluj bibliotekę kliencką Machine Learning Python
* dostęp do zestawów danych i przekazywanie ich, w tym instrukcje dotyczące uzyskiwania autoryzacji dostępu Azure Machine Learning zestawów danych ze środowiska lokalnego języka Python
* Uzyskiwanie dostępu do pośrednich zestawów danych z eksperymentów
* Użyj biblioteki klienta języka Python, aby wyliczyć zestawy danych, uzyskać dostęp do metadanych, odczytać zawartość zestawu danych, utworzyć nowe zestawy danych i zaktualizować istniejące zestawy danych

## <a name="prerequisites"></a>Wymagania wstępne
Biblioteka klienta języka Python została przetestowana w następujących środowiskach:

* Windows, Mac i Linux
* Python 2,7, 3,3 i 3,4

Ma zależność od następujących pakietów:

* żądań
* Python — dateutil
* Pandas

Zalecamy używanie dystrybucji języka Python, takiej jak [Anaconda](http://continuum.io/downloads#all) lub [koroner](https://store.enthought.com/downloads/), która jest dostarczana z zainstalowanymi w języku Python, IPython i trzema wymienionymi powyżej pakietami. Chociaż IPython nie jest ściśle wymagane, jest to doskonałe środowisko do interaktywnego manipulowania danymi i wizualizacji danych.

### <a name="installation"></a>Jak zainstalować bibliotekę kliencką Azure Machine Learning Python
Aby wykonać zadania opisane w tym temacie, należy również zainstalować bibliotekę kliencką Azure Machine Learning języka Python. Jest on dostępny w [indeksie pakietu języka Python](https://pypi.python.org/pypi/azureml). Aby zainstalować ją w środowisku języka Python, uruchom następujące polecenie w lokalnym środowisku języka Python:

    pip install azureml

Alternatywnie możesz pobrać i zainstalować ze źródeł w serwisie [GitHub](https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python).

    python setup.py install

Jeśli na komputerze jest zainstalowany program git, możesz zainstalować go bezpośrednio z repozytorium git przy użyciu narzędzia PIP:

    pip install git+https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python.git


## <a name="datasetAccess"></a>Używanie fragmentów kodu Studio do uzyskiwania dostępu do zestawów danych
Biblioteka klienta języka Python zapewnia programistyczny dostęp do istniejących zestawów danych z eksperymentów, które zostały uruchomione.

W interfejsie sieci Web programu Studio można generować fragmenty kodu zawierające wszystkie informacje niezbędne do pobrania i deserializacji zestawów danych jako obiektów Pandas Dataframe na komputerze lokalnym.

### <a name="security"></a>Zabezpieczenia dostępu do danych
Fragmenty kodu dostarczone przez Studio do użycia z biblioteką klienta języka Python obejmują identyfikator obszaru roboczego i token autoryzacji. Zapewniają one pełen dostęp do obszaru roboczego i muszą być chronione, takie jak hasło.

Ze względów bezpieczeństwa funkcja fragmentu kodu jest dostępna tylko dla użytkowników, którzy mają ustawioną rolę **właściciel** dla obszaru roboczego. Twoja rola jest wyświetlana w Azure Machine Learning Studio (klasyczny) na stronie **Użytkownicy** w obszarze **Ustawienia**.

![Bezpieczeństwo][security]

Jeśli rola nie jest ustawiona jako **właściciel**, możesz wysłać żądanie do osoby, która ma zostać zaproszona jako właściciel, lub poprosić właściciela obszaru roboczego o udostępnienie fragmentu kodu.

Aby uzyskać Token autoryzacji, można wykonać jedną z następujących czynności:

* Poproszenie o token od właściciela. Właściciele mogą uzyskać dostęp do tokenów autoryzacji ze strony ustawień obszaru roboczego w programie Studio. Wybierz pozycję **Ustawienia** w okienku po lewej stronie, a następnie kliknij pozycję **tokeny autoryzacji** , aby zobaczyć token podstawowy i pomocniczy. Mimo że tokeny uwierzytelniania podstawowego lub pomocniczego mogą być używane we fragmencie kodu, zaleca się, aby właściciele współdzielą tokeny autoryzacji pomocniczej.

![Tokeny autoryzacji](./media/python-data-access/ml-python-access-settings-tokens.png)

* Poproszenie o podwyższenie poziomu roli właściciela. Aby to zrobić, bieżący właściciel obszaru roboczego musi najpierw usunąć użytkownika z obszaru roboczego, a następnie ponownie zaprosić użytkownika jako właściciela.

Gdy deweloperzy uzyskali identyfikator obszaru roboczego i token autoryzacji, będą mogli uzyskać dostęp do obszaru roboczego przy użyciu fragmentu kodu, niezależnie od ich roli.

Tokeny autoryzacji są zarządzane na stronie **tokeny autoryzacji** w obszarze **Ustawienia**. Można je ponownie wygenerować, ale ta procedura odwołuje dostęp do poprzedniego tokenu.

### <a name="accessingDatasets"></a>Dostęp do zestawów danych z lokalnej aplikacji języka Python
1. W Machine Learning Studio kliknij pozycję **zestawy danych** na pasku nawigacyjnym po lewej stronie.
2. Wybierz zestaw danych, do którego chcesz uzyskać dostęp. Możesz wybrać dowolny z zestawów danych z listy **moje zbiory danych** lub z listy **przykładów** .
3. Na dolnym pasku narzędzi kliknij pozycję **Generuj kod dostępu do danych**. Jeśli dane są w formacie niezgodnym z biblioteką klienta języka Python, ten przycisk jest wyłączony.
   
    ![Zestawy danych][datasets]
4. Wybierz fragment kodu z wyświetlonego okna i skopiuj go do Schowka.
   
    ![Przycisk generowania kodu dostępu do danych][dataset-access-code]
5. Wklej kod do notesu lokalnej aplikacji w języku Python.
   
    ![Wklej kod do notesu][ipython-dataset]

## <a name="accessingIntermediateDatasets"></a>Uzyskiwanie dostępu do pośrednich zestawów danych z Machine Learning eksperymenty
Po uruchomieniu eksperymentu w Machine Learning Studio można uzyskać dostęp do pośrednich zestawów danych z węzłów wyjściowych modułów. Pośrednie zestawy danych to dane, które zostały utworzone i użyte do pośrednich etapów, gdy narzędzie modelu zostało uruchomione.

Do pośrednich zestawów danych można uzyskać dostęp, o ile jest on zgodny z biblioteką klienta języka Python.

Obsługiwane są następujące formaty (stałe dla tych, które znajdują się w klasie `azureml.DataTypeIds`):

* Formacie
* GenericCSV
* GenericTSV
* GenericCSVNoHeader
* GenericTSVNoHeader

Możesz określić format, ustawiając kursor nad węzłem wyjściowym modułu. Jest wyświetlana wraz z nazwą węzła w etykietce narzędzia.

Niektóre moduły, takie jak moduł [Split][split] , są wyprowadzane do formatu o nazwie `Dataset`, który nie jest obsługiwany przez bibliotekę kliencką języka Python.

![Format zestawu danych][dataset-format]

Musisz użyć modułu konwersji, takiego jak [Convert to CSV][convert-to-csv], aby uzyskać dane wyjściowe do obsługiwanego formatu.

![Format GenericCSV][csv-format]

W poniższych krokach przedstawiono przykład tworzenia eksperymentu, uruchamiania go i uzyskiwania dostępu do pośredniego zestawu danych.

1. Utwórz nowy eksperyment.
2. Wstaw **binarny moduł zestawu danych klasyfikacji dochodów z spisu dla dorosłych** .
3. Wstaw moduł [podzielony][split] i Połącz jego dane wejściowe z danymi wyjściowymi modułu DataSet.
4. Wstaw moduł [Convert to CSV][convert-to-csv] i Połącz jego dane wejściowe z jednym z danych wyjściowych modułu [Split][split] .
5. Zapisz eksperyment, uruchom go i poczekaj na zakończenie jego działania.
6. Kliknij węzeł wyjście w module [Konwertuj na wolumin CSV][convert-to-csv] .
7. Po wyświetleniu menu kontekstowego wybierz pozycję **Generuj kod dostępu do danych**.
   
    ![Menu kontekstowe][experiment]
8. Wybierz fragment kodu i skopiuj go do schowka z wyświetlonego okna.
   
    ![Generuj kod dostępu z menu kontekstowego][intermediate-dataset-access-code]
9. Wklej kod w notesie.
   
    ![Wklej kod do notesu][ipython-intermediate-dataset]
10. Możesz wizualizować dane przy użyciu matplotlib. Spowoduje to wyświetlenie w histogramie kolumny wiek:
    
    ![Razem][ipython-histogram]

## <a name="clientApis"></a>Korzystanie z Machine Learning biblioteki klienta języka Python w celu uzyskiwania dostępu do zestawów danych, ich odczytywania, tworzenia i zarządzania nimi
### <a name="workspace"></a>Obszar roboczy
Obszar roboczy jest punktem wejścia dla biblioteki klienta języka Python. Podaj klasę `Workspace` z identyfikatorem obszaru roboczego i tokenem autoryzacji, aby utworzyć wystąpienie:

    ws = Workspace(workspace_id='4c29e1adeba2e5a7cbeb0e4f4adfb4df',
                   authorization_token='f4f3ade2c6aefdb1afb043cd8bcf3daf')


### <a name="enumerate-datasets"></a>Wyliczanie zestawów danych
Aby wyliczyć wszystkie zestawy danych w danym obszarze roboczym:

    for ds in ws.datasets:
        print(ds.name)

Aby wyliczyć tylko zestawy danych utworzone przez użytkownika:

    for ds in ws.user_datasets:
        print(ds.name)

Aby wyliczyć tylko przykładowe zestawy danych:

    for ds in ws.example_datasets:
        print(ds.name)

Dostęp do zestawu danych można uzyskać przy użyciu nazwy (w przypadku uwzględniania wielkości liter):

    ds = ws.datasets['my dataset name']

Lub dostęp do niego można uzyskać za pomocą indeksu:

    ds = ws.datasets[0]


### <a name="metadata"></a>Metadane
Zestawy danych zawierają metadane, a także zawartość. (Pośrednie zestawy danych są wyjątkiem od tej reguły i nie mają żadnych metadanych).

Niektóre wartości metadanych są przypisywane przez użytkownika podczas tworzenia:

    print(ds.name)
    print(ds.description)
    print(ds.family_id)
    print(ds.data_type_id)

Inne są wartościami przypisanymi przez usługę Azure ML:

    print(ds.id)
    print(ds.created_date)
    print(ds.size)

Zapoznaj się z klasą `SourceDataset`, aby uzyskać więcej informacji na temat dostępnych metadanych.

### <a name="read-contents"></a>Odczytaj zawartość
Fragmenty kodu udostępniane przez Machine Learning Studio (klasyczne) automatycznie pobierają i deserializacjiją zestaw danych do obiektu Pandas Dataframe. Jest to realizowane z użyciem metody `to_dataframe`:

    frame = ds.to_dataframe()

Jeśli wolisz pobrać pierwotne dane i wykonać deserializacji samodzielnie, to jest opcja. Obecnie jest to jedyna opcja dla formatów takich jak "ARFF", które nie mogą deserializować biblioteki klienta języka Python.

Aby odczytać zawartość jako tekst:

    text_data = ds.read_as_text()

Aby odczytać zawartość jako plik binarny:

    binary_data = ds.read_as_binary()

Możesz również po prostu otworzyć strumień do zawartości:

    with ds.open() as file:
        binary_data_chunk = file.read(1000)


### <a name="create-a-new-dataset"></a>Utwórz nowy zestaw danych
Biblioteka klienta języka Python umożliwia przekazywanie zestawów danych z programu w języku Python. Te zestawy danych są następnie dostępne do użycia w Twoim obszarze roboczym.

Jeśli masz dane w Pandas Dataframe, użyj następującego kodu:

    from azureml import DataTypeIds

    dataset = ws.datasets.add_from_dataframe(
        dataframe=frame,
        data_type_id=DataTypeIds.GenericCSV,
        name='my new dataset',
        description='my description'
    )

Jeśli dane są już serializowane, można użyć:

    from azureml import DataTypeIds

    dataset = ws.datasets.add_from_raw_data(
        raw_data=raw_data,
        data_type_id=DataTypeIds.GenericCSV,
        name='my new dataset',
        description='my description'
    )

Biblioteka klienta języka Python jest w stanie serializować pandasą ramkę danych do następujących formatów (stałe dla nich znajdują się w klasie `azureml.DataTypeIds`):

* Formacie
* GenericCSV
* GenericTSV
* GenericCSVNoHeader
* GenericTSVNoHeader

### <a name="update-an-existing-dataset"></a>Aktualizowanie istniejącego zestawu danych
Jeśli próbujesz przekazać nowy zestaw danych o nazwie zgodnej z istniejącym zestawem danych, należy uzyskać błąd konfliktu.

Aby zaktualizować istniejący zestaw danych, należy najpierw pobrać odwołanie do istniejącego zestawu danych:

    dataset = ws.datasets['existing dataset']

    print(dataset.data_type_id) # 'GenericCSV'
    print(dataset.name)         # 'existing dataset'
    print(dataset.description)  # 'data up to jan 2015'

Następnie użyj `update_from_dataframe` do serializacji i Zastąp zawartość zestawu danych na platformie Azure:

    dataset = ws.datasets['existing dataset']

    dataset.update_from_dataframe(frame2)

    print(dataset.data_type_id) # 'GenericCSV'
    print(dataset.name)         # 'existing dataset'
    print(dataset.description)  # 'data up to jan 2015'

Jeśli chcesz serializować dane w innym formacie, określ wartość opcjonalnego parametru `data_type_id`.

    from azureml import DataTypeIds

    dataset = ws.datasets['existing dataset']

    dataset.update_from_dataframe(
        dataframe=frame2,
        data_type_id=DataTypeIds.GenericTSV,
    )

    print(dataset.data_type_id) # 'GenericTSV'
    print(dataset.name)         # 'existing dataset'
    print(dataset.description)  # 'data up to jan 2015'

Opcjonalnie można ustawić nowy opis, określając wartość parametru `description`.

    dataset = ws.datasets['existing dataset']

    dataset.update_from_dataframe(
        dataframe=frame2,
        description='data up to feb 2015',
    )

    print(dataset.data_type_id) # 'GenericCSV'
    print(dataset.name)         # 'existing dataset'
    print(dataset.description)  # 'data up to feb 2015'

Opcjonalnie możesz ustawić nową nazwę, określając wartość parametru `name`. Od teraz pobierasz zestaw danych tylko przy użyciu nowej nazwy. Poniższy kod aktualizuje dane, nazwę i opis.

    dataset = ws.datasets['existing dataset']

    dataset.update_from_dataframe(
        dataframe=frame2,
        name='existing dataset v2',
        description='data up to feb 2015',
    )

    print(dataset.data_type_id)                    # 'GenericCSV'
    print(dataset.name)                            # 'existing dataset v2'
    print(dataset.description)                     # 'data up to feb 2015'

    print(ws.datasets['existing dataset v2'].name) # 'existing dataset v2'
    print(ws.datasets['existing dataset'].name)    # IndexError

Parametry `data_type_id`, `name` i `description` są opcjonalne i domyślne dla ich poprzedniej wartości. Parametr `dataframe` jest zawsze wymagany.

Jeśli dane są już serializowane, użyj `update_from_raw_data` zamiast `update_from_dataframe`. Jeśli przejdziesz tylko do `raw_data` zamiast `dataframe`, działa to w podobny sposób.

<!-- Images -->
[security]:./media/python-data-access/security.png
[dataset-format]:./media/python-data-access/dataset-format.png
[csv-format]:./media/python-data-access/csv-format.png
[datasets]:./media/python-data-access/datasets.png
[dataset-access-code]:./media/python-data-access/dataset-access-code.png
[ipython-dataset]:./media/python-data-access/ipython-dataset.png
[experiment]:./media/python-data-access/experiment.png
[intermediate-dataset-access-code]:./media/python-data-access/intermediate-dataset-access-code.png
[ipython-intermediate-dataset]:./media/python-data-access/ipython-intermediate-dataset.png
[ipython-histogram]:./media/python-data-access/ipython-histogram.png


<!-- Module References -->
[convert-to-csv]: https://msdn.microsoft.com/library/azure/faa6ba63-383c-4086-ba58-7abf26b85814/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/

