---
title: Tworzenie zadań strumienia Spark o wysokiej dostępności w ramach PRZĘDZy — Azure HDInsight
description: Jak skonfigurować Apache Spark przesyłania strumieniowego w scenariuszu wysokiej dostępności w usłudze Azure HDInsight
ms.service: hdinsight
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.topic: conceptual
ms.custom: hdinsightactive
ms.date: 01/26/2018
ms.openlocfilehash: 9424ebbd4ed2e1536a10d77a88257bad948628e2
ms.sourcegitcommit: 083aa7cc8fc958fc75365462aed542f1b5409623
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 09/11/2019
ms.locfileid: "70915408"
---
# <a name="create-high-availability-apache-spark-streaming-jobs-with-yarn"></a>Tworzenie Apache Spark zadań przesyłania strumieniowego o wysokiej dostępności przy użyciu PRZĘDZy

[Apache Spark](https://spark.apache.org/) Przesyłanie strumieniowe umożliwia wdrożenie skalowalnych aplikacji o wysokiej przepływności i odpornych na uszkodzenia na potrzeby przetwarzania strumieni danych. Aplikacje Spark Streaming można połączyć w klastrze usługi HDInsight Spark z różnymi źródłami danych, takimi jak Azure Event Hubs, Azure IoT Hub, [Apache Kafka](https://kafka.apache.org/), [Apache Flume](https://flume.apache.org/), Twitter, [ZEROMQ](http://zeromq.org/), RAW Sockets TCP lub przez monitorowanie [ Apache Hadoop](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html) systemu plików HDFS dla zmian. Funkcja przesyłania strumieniowego Spark obsługuje odporność na uszkodzenia z gwarancją, że każde dane zdarzenie jest przetwarzane dokładnie jeden raz, nawet w przypadku awarii węzła.

Usługa Spark Streaming tworzy długotrwałe zadania, w których można zastosować przekształcenia do danych, a następnie wypchnąć wyniki do systemów plików, baz danych, pulpitów nawigacyjnych i konsoli programu. Procesy przesyłania strumieniowego Spark przetwarzają mikropartie danych, tworząc najpierw partię zdarzeń w określonym przedziale czasu. Następnie ta partia jest wysyłana na potrzeby przetwarzania i wygenerowania danych wyjściowych. Przedziały czasu partii są zwykle zdefiniowane w częściach sekundy.

![Przesyłanie strumieniowe Spark](./media/apache-spark-streaming-high-availability/spark-streaming.png)

## <a name="dstreams"></a>DStreams

Przesyłanie strumieniowe Spark reprezentuje ciągły strumień danych przy użyciu *strumienia zdyskretyzowanej* (DStream). Tę DStreamę można utworzyć na podstawie źródeł danych wejściowych, takich jak Event Hubs lub Kafka, lub stosując przekształcenia na innym DStream. Gdy zdarzenie dociera do aplikacji Spark streaming, zdarzenie jest przechowywane w niezawodny sposób. Oznacza to, że dane zdarzenia są replikowane, dzięki czemu wiele węzłów ma kopię. Gwarantuje to, że awaria jednego węzła nie spowoduje utraty zdarzenia.

Rdzeń Spark używa *rozproszonych zestawów danych* (odporne). Odporne Dystrybuuj dane między wieloma węzłami w klastrze, gdzie każdy węzeł ogólnie przechowuje swoje dane w pamięci w celu uzyskania najlepszej wydajności. Każdy RDD reprezentuje zdarzenia zbierane w ramach interwału wsadowego. Gdy upłynie interwał wsadowy, przesyłanie strumieniowe w usłudze Spark generuje nowy RDD zawierający wszystkie dane z tego interwału. Ten ciągły zestaw odporne jest zbierany w DStream. Aplikacja do przesyłania strumieniowego Spark przetwarza dane przechowywane w RDD każdej partii.

![DStream platformy Spark](./media/apache-spark-streaming-high-availability/apache-spark-dstream.png)

## <a name="spark-structured-streaming-jobs"></a>Zadania przetwarzania strumieniowego platformy Spark

Funkcja przesyłania strumieniowego platformy Spark została wprowadzona w platformie Spark 2,0 jako aparat analityczny służący do przesyłania strumieniowego danych strukturalnych. Funkcja przesyłania strumieniowego platformy Spark używa interfejsów API aparatu wsadowego SparkSQL. Podobnie jak w przypadku przesyłania strumieniowego Spark, w przypadku przesyłania strumieniowego platformy Spark są uruchamiane obliczenia z przenoszonej porcji danych. Funkcja przesyłania strumieniowego platformy Spark reprezentuje strumień danych jako tabelę wejściową z nieograniczonymi wierszami. Oznacza to, że tabela wejściowa nadal rośnie po nadejściu nowych danych. Ta tabela wejściowa jest ciągle przetwarzana przez długotrwałe zapytanie, a wyniki są zapisywane do tabeli wyjściowej.

![Strumień strukturalny platformy Spark](./media/apache-spark-streaming-high-availability/structured-streaming.png)

W przypadku przesyłania strumieniowego ze strukturą dane docierają do systemu i są natychmiast pozyskiwane w tabeli wejściowej. Napisz zapytania, które wykonują operacje na tej tabeli wejściowej. Dane wyjściowe zapytania dają inną tabelę o nazwie tabela wyników. Tabela wyniki zawiera wyniki zapytania, z którego dane mają być wysyłane do zewnętrznego magazynu danych, takiego jak relacyjna baza danych. *Interwał wyzwalacza* określa czas, w którym dane są przetwarzane z tabeli wejściowej. Domyślnie proces przesyłania strumieniowego przetwarza dane zaraz po nadejściu. Można jednak skonfigurować wyzwalacz do uruchamiania na dłuższym interwale, dzięki czemu dane przesyłane strumieniowo są przetwarzane w partiach opartych na czasie. Dane w tabeli wyników mogą być całkowicie odświeżane za każdym razem, gdy są nowe dane, dzięki czemu zawiera wszystkie dane wyjściowe od momentu rozpoczęcia zapytania przesyłania strumieniowego (*tryb kompletny*) lub może zawierać tylko dane, które są nowe od momentu ostatniego uruchomienia zapytania ssed (*tryb Append*).

## <a name="create-fault-tolerant-spark-streaming-jobs"></a>Twórz odporne na błędy zadania przetwarzania strumieniowego Spark

Aby utworzyć środowisko o wysokiej dostępności dla zadań przesyłania strumieniowego platformy Spark, Zacznij od kodowania poszczególnych zadań do odzyskania w przypadku awarii. Takie zadania samoobsługowego odzyskiwania są odporne na uszkodzenia.

Odporne mają kilka właściwości, które pomagają w wysokiej dostępności i odpornych na błędy zadań przetwarzania strumieniowego Spark:

* Partie danych wejściowych przechowywanych w odporne jako DStream są automatycznie replikowane w pamięci pod kątem odporności na uszkodzenia.
* Dane utracone z powodu błędu procesu roboczego można obliczyć ponownie z replikowanych danych wejściowych w różnych procesach roboczych, o ile te węzły są dostępne.
* Szybkie odzyskiwanie błędów może wystąpić w ciągu sekundy, ponieważ odzyskiwanie z błędów/stragglers odbywa się za pośrednictwem obliczeń w pamięci.

### <a name="exactly-once-semantics-with-spark-streaming"></a>Semantyka dokładnie jednokrotna z funkcją przesyłania strumieniowego Spark

Aby utworzyć aplikację, która przetwarza każde zdarzenie raz (i tylko raz), należy wziąć pod uwagę, w jaki sposób wszystkie punkty systemowe awarii zostały uruchomione ponownie po wystąpieniu problemu, a także jak można uniknąć utraty danych. Semantyka dokładnie jednokrotne wymaga, aby w żadnym momencie żadne dane nie zostały utracone i że przetwarzanie komunikatów jest uruchamiane ponownie, niezależnie od tego, gdzie wystąpi awaria. Zobacz [Tworzenie zadań strumienia Spark z przetwarzaniem zdarzeń dokładnie raz](apache-spark-streaming-exactly-once.md).

## <a name="spark-streaming-and-apache-hadoop-yarn"></a>Przesyłanie strumieniowe Spark i Apache Hadoop

W usłudze HDInsight współpraca klastra jest koordynowana przez *inny* program. Projektowanie wysokiej dostępności dla przesyłania strumieniowego Spark obejmuje techniki przesyłania strumieniowego Spark, a także dla składników PRZĘDZy.  Poniżej przedstawiono przykładową konfigurację przy użyciu PRZĘDZy. 

![Architektura PRZĘDZy](./media/apache-spark-streaming-high-availability/yarn-arch.png)

W poniższych sekcjach opisano zagadnienia dotyczące projektowania tej konfiguracji.

### <a name="plan-for-failures"></a>Planowanie błędów

Aby utworzyć konfigurację PRZĘDZy dla wysokiej dostępności, należy zaplanować ewentualny błąd wykonawcy lub sterownika. Niektóre zadania przesyłania strumieniowego Spark obejmują również wymagania dotyczące gwarancji danych, które wymagają dodatkowej konfiguracji i instalacji. Na przykład aplikacja przesyłania strumieniowego może mieć wymóg biznesowy dla gwarancji o zerowej utracie danych pomimo dowolnego błędu występującego w systemie obsługującym przesyłanie strumieniowe lub klaster usługi HDInsight.

Jeśli **wykonawca** nie powiedzie się, jego zadania i odbiorniki zostaną automatycznie uruchomione ponownie przez platformę Spark, więc nie jest wymagana żadna zmiana konfiguracji.

Jeśli jednak **Sterownik** ulegnie awarii, wszystkie powiązane z nim Moduły wykonawcze zakończą się niepowodzeniem, a wszystkie odebrane bloki i wyniki obliczeń zostaną utracone. Aby odzyskać sprawność po awarii sterownika, należy użyć *punktów kontrolnych DStream* , jak opisano w temacie [Tworzenie zadań strumieniowych usługi Spark za pomocą przetwarzania zdarzeń dokładnie raz](apache-spark-streaming-exactly-once.md#use-checkpoints-for-drivers). Funkcja DStream Checkpoint okresowo zapisuje *ukierunkowany wykres acykliczne* (DAG) DStreams do magazynu odpornego na błędy, takiego jak usługa Azure Storage.  Tworzenie punktów kontrolnych umożliwia przesyłanie strumieniowe platformy Spark w celu ponownego uruchomienia nieuszkodzonego sterownika z informacji o punkcie kontrolnym.  Ten sterownik uruchamia ponownie uruchamia nowe wykonawcy, a także ponownie uruchamia odbiorniki.

Aby odzyskać sterowniki z DStream Checkpoint:

* Skonfiguruj automatyczne ponowne uruchamianie sterowników w PRZĘDZe z ustawieniem `yarn.resourcemanager.am.max-attempts`konfiguracji.
* Ustaw katalog punktów kontrolnych w systemie plików zgodnym z systemem `streamingContext.checkpoint(hdfsDirectory)`HDFS przy użyciu programu.
* Restrukturyzacja kodu źródłowego do używania punktów kontrolnych do odzyskiwania, na przykład:

    ```scala
        def creatingFunc() : StreamingContext = {
            val context = new StreamingContext(...)
            val lines = KafkaUtils.createStream(...)
            val words = lines.flatMap(...)
            ...
            context.checkpoint(hdfsDir)
        }

        val context = StreamingContext.getOrCreate(hdfsDir, creatingFunc)
        context.start()
    ```

* Skonfiguruj odzyskiwanie utraconych danych, włączając dziennik zapisu (WAL) w programie `sparkConf.set("spark.streaming.receiver.writeAheadLog.enable","true")`, i Wyłącz replikację w pamięci dla danych wejściowych DStreams z. `StorageLevel.MEMORY_AND_DISK_SER`

Aby podsumować przy użyciu punktów kontrolnych + WAL i niezawodnych odbiorców, będzie można dostarczyć "co najmniej raz" odzyskiwania danych:

* Dokładnie raz, tak długo, jak odebrane dane nie są tracone i wyjścia są idempotentne lub transakcyjne.
* Dokładnie raz, przy użyciu nowej metody Kafka Direct, która używa Kafka jako zreplikowanego dziennika, zamiast używać odbiorników lub WALs.

### <a name="typical-concerns-for-high-availability"></a>Typowe problemy dotyczące wysokiej dostępności

* Trudniejsze jest monitorowanie zadań przesyłania strumieniowego niż zadań wsadowych. Zadania przesyłania strumieniowego Spark są zwykle długotrwałe i PRZĘDZa nie agreguje dzienników do momentu zakończenia zadania.  Punkty kontrolne platformy Spark są tracone podczas uaktualniania aplikacji lub platformy Spark, a podczas uaktualniania należy wyczyścić katalog punktów kontrolnych.

* Skonfiguruj tryb klastra PRZĘDZy, aby uruchamiać sterowniki nawet wtedy, gdy klient ulegnie awarii. Aby skonfigurować automatyczne ponowne uruchamianie dla sterowników:

    ```
    spark.yarn.maxAppAttempts = 2
    spark.yarn.am.attemptFailuresValidityInterval=1h
    ```

* Platforma Spark i interfejs użytkownika funkcji przesyłania strumieniowego Spark mają konfigurowalny system metryk. Możesz również użyć dodatkowych bibliotek, takich jak grafit/Grafana, aby pobrać metryki pulpitu nawigacyjnego, takie jak "liczba rekordów przetworzonych", "użycie pamięci/GC na sterowniku & wykonywania", "całkowitego opóźnienia", "użycie klastra" i tak dalej. W przypadku przesyłania strumieniowego ze strukturą w wersji 2,1 `StreamingQueryListener` lub nowszej można użyć programu, aby zebrać dodatkowe metryki.

* Należy dzielić długotrwałe zadania.  Gdy aplikacja do przesyłania strumieniowego Spark jest przesyłana do klastra, należy zdefiniować kolejkę PRZĘDZy, w której uruchomiono zadanie. Można użyć [harmonogramu pojemności przędzy](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html) do przesyłania długotrwałych zadań do oddzielnych kolejek.

* Bezpiecznie zamykaj aplikację przesyłania strumieniowego. Jeśli Twoje przesunięcia są znane i wszystkie Stany aplikacji są przechowywane zewnętrznie, można programowo zatrzymać aplikację przesyłania strumieniowego w odpowiednim miejscu. Jedną z technik jest użycie "punktów zaczepienia wątku" w Spark, sprawdzając flagę zewnętrzną co *n* sekund. Można również użyć *pliku znacznika* , który jest tworzony w systemie plików HDFS podczas uruchamiania aplikacji, a następnie usunąć go, gdy chcesz zatrzymać. W przypadku podejścia do pliku znacznika Użyj oddzielnego wątku w aplikacji Spark, który wywołuje kod podobny do tego:

    ```scala
    streamingContext.stop(stopSparkContext = true, stopGracefully = true)
    // to be able to recover on restart, store all offsets in an external database
    ```

## <a name="next-steps"></a>Następne kroki

* [Omówienie Apache Spark Streaming](apache-spark-streaming-overview.md)
* [Twórz Apache Spark zadania przesyłania strumieniowego z przetwarzaniem zdarzeń dokładnie raz](apache-spark-streaming-exactly-once.md)
* [Długotrwałe wykonywanie zadań przesyłania strumieniowego Apache Spark na PRZĘDZe](https://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/) 
* [Przesyłanie strumieniowe strukturalne: Semantyka odporna na uszkodzenia](https://spark.apache.org/docs/2.1.0/structured-streaming-programming-guide.html#fault-tolerance-semantics)
* [Zdyskretyzowanej strumienie: Model odporny na uszkodzenia dla skalowalnego przetwarzania strumieniowego](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-259.pdf)
